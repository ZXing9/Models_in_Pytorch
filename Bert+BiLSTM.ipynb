{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建实例化模型，添加dropout层，和dense层来获得模型的最终输出。 \n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.config = BertConfig.from_pretrained('./bert/bert-mini/bert_config.json', output_hidden_states=True)\n",
    "        self.l1 = BertModel.from_pretrained('./bert/bert-mini/pytorch_model.bin', config=self.config)\n",
    "        ## 双向LSTM层\n",
    "        self.bilstm1 = torch.nn.LSTM(512, 64, 1, bidirectional=True)\n",
    "        # 全连接层\n",
    "        self.l2 = torch.nn.Linear(128, 64)\n",
    "        # 激活函数\n",
    "        self.a1 = torch.nn.ReLU()\n",
    "        # dropout\n",
    "        self.l3 = torch.nn.Dropout(0.3)\n",
    "        self.l4 = torch.nn.Linear(64, 14)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        # 将结果送入到各层中去训练\n",
    "        sequence_output, pooler_output, hidden_states= self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        # [bs, 200, 256]  [bs,256]\n",
    "        bs = len(sequence_output)\n",
    "        h12 = hidden_states[-1][:,0].view(1,bs,256)\n",
    "        h11 = hidden_states[-2][:,0].view(1,bs,256)\n",
    "        concat_hidden = torch.cat((h12,h11),2)\n",
    "        x, _ = self.bilstm1(concat_hidden)\n",
    "        x = self.l2(x.view(bs,128))\n",
    "        x = self.a1(x)\n",
    "        x = self.l3(x)\n",
    "        output = self.l4(x)\n",
    "        return output\n",
    "\n",
    "net = BERTClass()\n",
    "net.to(device)"
   ]
  }
 ]
}